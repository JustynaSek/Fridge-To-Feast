Project: Fridge to Feast (AI Recipe Generator)
Objective: Develop a Next.js application that generates personalized recipes based on user-provided ingredient lists (text) or multiple photos of refrigerator/pantry contents. The application will feature deep personalization through user preferences and a personal RAG system built on saved recipes.

Core Technologies:

Frontend: Next.js (React)
Styling: Tailwind CSS
Deployment: Vercel
LLM Integration: OpenAI API (GPT models), LangChain (for agentic workflows & conversational memory)
Image Processing: Google Cloud Vision API (for ingredient identification from images)
Primary Database (Relational/Document/Vector): Choose ONE in Phase 3.1: Neon (PostgreSQL with pgvector extension) OR Upstash (Redis with Vector Search capabilities). This decision will guide database integration for all subsequent phases.
Caching/Rate Limiting: Upstash Redis (for general caching, not vector search unless chosen as primary DB).

CURRENT PROJECT STATUS (Updated January 2025)
==============================================

âœ… COMPLETED PHASES:
- Phase 1: Foundation & Text-Based Recipes (MVP) - COMPLETE
- Phase 2: Image Recognition & Enhanced Recipe Generation - COMPLETE

âœ… IMPLEMENTED FEATURES:
- Multi-image upload with drag & drop functionality
- Google Cloud Vision API integration for ingredient detection
- OpenAI GPT-4 integration for recipe generation
- Intelligent ingredient filtering and deduplication
- Individual image deletion and bulk clear operations
- Recipe display with clear functionality
- Responsive design with dark mode support
- Error handling and loading states
- Environment-based configuration for API keys

âœ… TECHNICAL ACHIEVEMENTS:
- Functional state management with useCallback and useEffect
- Image optimization and compression
- Smart deduplication of similar ingredients
- Confidence-based detection for cluttered scenes
- Comprehensive logging and debugging
- GitHub repository with detailed documentation

ðŸ”„ CURRENT FOCUS: User Experience Enhancement
============================================

Phase 2.5: User Experience & Interface Improvements (CURRENT PHASE)
Goal: Transform the functional application into a delightful, user-friendly experience with enhanced visual design, better feedback, and improved usability.

Epic 2.5.1: Enhanced Visual Design & User Interface

Task 2.5.1.1: Improve Header and Branding
Action: Enhance the main header with:
- Add a logo/icon (chef hat, cooking pot, or food-related icon)
- Improve typography and spacing
- Add subtle animations or micro-interactions
- Consider adding a tagline or brief description

Outcome: Professional, branded header that establishes trust and sets the tone for the application.

Task 2.5.1.2: Implement Loading States and Animations
Action: Add sophisticated loading states:
- Skeleton loading for recipe generation
- Progress indicators for image processing
- Smooth transitions between states
- Loading spinners with contextual messages
- Success animations when recipes are generated

Outcome: Users receive clear feedback about what's happening and when operations complete.

Task 2.5.1.3: Enhanced Error Handling and User Feedback
Action: Improve error messages and user guidance:
- Replace generic error messages with helpful, actionable suggestions
- Add tooltips and help text for complex features
- Implement toast notifications for success/error states
- Provide specific guidance for common issues (e.g., "Try uploading clearer images" for low-confidence detections)
- Add retry mechanisms for failed operations

Outcome: Users understand what went wrong and how to fix it, reducing frustration and support requests.

Epic 2.5.2: Mobile Experience Optimization

Task 2.5.2.1: Mobile-First Responsive Design
Action: Optimize the interface for mobile devices:
- Ensure all touch targets are at least 44px
- Improve image upload experience on mobile
- Optimize text input for mobile keyboards
- Test and improve drag-and-drop on touch devices
- Ensure proper viewport handling and zoom behavior

Outcome: Seamless experience across all device sizes, with mobile as a first-class citizen.

Task 2.5.2.2: Touch-Friendly Interactions
Action: Enhance touch interactions:
- Larger buttons and interactive elements
- Swipe gestures for image management
- Improved scrolling and navigation
- Better handling of mobile-specific events

Outcome: Intuitive touch interactions that feel native on mobile devices.

Epic 2.5.3: User Flow and Navigation Improvements

Task 2.5.3.1: Implement Step-by-Step Wizard Interface
Action: Create a guided experience:
- Break down the process into clear steps
- Add progress indicators
- Provide contextual help at each step
- Allow users to go back and modify previous steps
- Show clear next actions

Outcome: Users understand exactly what to do at each step, reducing confusion and improving completion rates.

Task 2.5.3.2: Add Quick Actions and Shortcuts
Action: Implement time-saving features:
- Quick ingredient suggestions based on common items
- Recent ingredients or recipes
- Keyboard shortcuts for power users
- One-click actions for common tasks

Outcome: Faster, more efficient user workflows for both new and experienced users.

Epic 2.5.4: Smart Features and Intelligence

Task 2.5.4.1: Implement Ingredient Suggestions and Autocomplete
Action: Add intelligent ingredient assistance:
- Autocomplete for ingredient names
- Suggestions based on what's commonly available
- Smart corrections for typos
- Grouping of related ingredients

Outcome: Users can input ingredients faster and more accurately.

Task 2.5.4.2: Add Recipe Favorites and History
Action: Implement basic recipe management:
- Allow users to "like" or favorite recipes
- Show recently generated recipes
- Basic recipe history (local storage initially)
- Quick access to previous results

Outcome: Users can easily find and reuse recipes they enjoyed.

Epic 2.5.5: Interactive Elements and Micro-interactions

Task 2.5.5.1: Add Animated Transitions
Action: Implement smooth animations:
- Page transitions
- Component mounting/unmounting
- State changes
- Loading states
- Success/error feedback

Outcome: Polished, professional feel that enhances user engagement.

Task 2.5.5.2: Implement Micro-interactions
Action: Add delightful small interactions:
- Button hover effects
- Image preview animations
- Checkbox animations
- Form validation feedback
- Success celebrations

Outcome: Engaging, delightful user experience that encourages continued use.

FUTURE PHASES (After UX Improvements)
=====================================

Phase 3: Advanced AI, Comprehensive Personalization & Saved Recipes
Goal: Implement user accounts, comprehensive preferences, and the foundational elements for personalized RAG leveraging Neon or Upstash.

Epic 3.1: User Accounts & Comprehensive Preferences (DB)

Task 3.1.1: Database Selection Technical Spike:
Action: Conduct a small Proof-of-Concept (PoC) comparing Neon (PostgreSQL with pgvector) and Upstash (Redis with Vector Search). Focus on:
- Ease of integration with Next.js API Routes for both traditional and vector data.
- Developer experience for multi-tenancy (user isolation).
- Initial cost estimate for anticipated scale (thousands of users, hundreds of saved recipes each).
- Basic performance for single-user vector search (initial testing).

Outcome: Final decision on the primary database solution. Update Core Technologies section accordingly.

Task 3.1.2: Implement User Authentication.
Action: Integrate Clerk (recommended for ease of use with Next.js) or Auth.js. Implement sign-up, login, and session management.

Outcome: Secure user authentication established.

Task 3.1.3: Design and Implement User Profile/Preferences Schema.
Action: Create a users table/collection in the chosen primary database (Neon or Upstash).
Define fields: id (primary key/hash key), email, auth_provider_id, preferences (JSONB for Neon, hash field for Upstash Redis).
preferences should store structured data like: likesSalty: boolean, spiceLevel: number (1-5), preferredCuisines: string[], dietaryRestrictions: string[], allergies: string[], mealPace: 'quick' | 'leisurely', etc.

Outcome: Database schema for user profiles and preferences defined.

Task 3.1.4: Develop User Preferences UI and API.
Action: Create a dedicated pages/settings/preferences.tsx (Client Component) with a user-friendly form to set preferences. Use useState for form input, submit via API.
Develop pages/api/user/preferences.ts (API Route) to handle authenticated GET (retrieve) and POST/PUT (save) operations with the users table/collection.

Outcome: Users can manage and store their culinary preferences via UI.

Task 3.1.5: Integrate User Preferences into LLM Prompt.
Action: Modify pages/api/generate-recipe.ts to:
- Before calling the LLM, fetch the current authenticated user's preferences from the database.
- Dynamically inject these preferences into the LLM's system prompt.

PRECISE SYSTEM PROMPT EXAMPLE (Initial Generation):
You are an expert, creative, and friendly chef named "Chef Feast." Your goal is to help the user cook delicious meals using available ingredients, respecting their preferences.

<user_preferences>
{/* Dynamically insert user's preferences JSON here */}
{ "likesSalty": true, "spiceLevel": 4, "preferredCuisines": ["Mediterranean", "Asian"], "dietaryRestrictions": ["gluten-free"], "allergies": ["nuts"], "mealPace": "quick" }
</user_preferences>

<current_conversation_history>
{/* Leave empty for initial generation, populated by LangChain for modifications */}
</current_conversation_history>

Instructions:
1. Based on the provided ingredients and the user's preferences, suggest 2-3 unique and practical recipes.
2. For each recipe, provide:
   a. A creative and enticing title.
   b. A brief, inviting description.
   c. A concise list of required ingredients (including quantities, if reasonable assumptions can be made). Prioritize using the user's provided ingredients.
   d. Clear, step-by-step cooking instructions.
   e. An estimated preparation time and cooking time.
3. Ensure recipes strictly adhere to "dietaryRestrictions" and "allergies". Adapt "spiceLevel", "likesSalty", "preferredCuisines", and "mealPace" as much as possible.
4. If an ingredient list seems incomplete or ambiguous for good recipes, suggest logical additions or ask for clarification within your response.
5. Format your response as a JSON array of recipe objects. Each recipe object must have the keys: "title", "description", "ingredients", "instructions", "prepTime", "cookTime".

Example JSON structure:
[
  {
    "title": "Zesty Lemon Herb Chicken with Roasted Broccoli",
    "description": "A quick and flavorful gluten-free dish...",
    "ingredients": ["2 boneless, skinless chicken breasts", "1 head broccoli", "1 lemon", ...],
    "instructions": "1. Preheat oven... 2. Season chicken...",
    "prepTime": "15 min",
    "cookTime": "25 min"
  }
]

Outcome: LLM generates recipes personalized by user's stored preferences.

Epic 3.2: Saved Recipes & Personal RAG Embedding Generation

Task 3.2.1: Design Saved Recipe Schema (with Vector Integration).
Action: Create a saved_recipes table/collection in the chosen primary database.
Define fields: id, user_id, title, ingredients_list: string[], instructions: string, original_llm_response: JSON, created_at.

Vector Column/Field:
- If Neon: Add an embedding VECTOR(dimensions) column (e.g., VECTOR(1536) for OpenAI embeddings). Create an HNSW index on this column for efficient similarity search.
- If Upstash: Define key structure for raw recipe data (e.g., user:<user_id>:recipe:<recipe_id>) and ensure embeddings are stored in a designated Upstash Vector index with user_id as metadata or within a user-specific namespace.

Outcome: Database schema ready for saved recipes and their corresponding embeddings.

Task 3.2.2: Implement "Save Recipe" Functionality.
Action: Add a "Save Recipe" button to components/RecipeDisplay.tsx.
Develop pages/api/user/save-recipe.ts (API Route). This route will:
- Receive the recipe data from the frontend.
- Store the recipe details (non-embedding fields) in the saved_recipes table/collection.
- Call an embedding model (e.g., OpenAI text-embedding-ada-002) to generate an embedding for the recipe's core content (e.g., title + " " + ingredients_list.join(", ") + " " + instructions).
- Store the embedding with user_id linkage into the pgvector table or Upstash Vector index.

Outcome: Users can save recipes, and their embeddings are stored in their personal vector space within the chosen database.

Task 3.2.3: Implement View Saved Recipes.
Action: Create pages/user/saved-recipes.tsx (Client Component). Fetch and display a list of the authenticated user's saved recipes (from the traditional part of the database). Implement UI to view full recipe details.

Outcome: User can access their personalized recipe library.

Epic 3.3: Agentic Workflow & Conversational Recipe Modification

Task 3.3.1: Implement Conversational Memory with LangChain.
Action: In pages/api/generate-recipe.ts (or pages/api/modify-recipe.ts), integrate LangChain's conversational memory (e.g., ConversationBufferMemory or ConversationSummaryMemory) to pass previous messages to the LLM within a single session.

Outcome: LLM remembers the context of the current recipe generation/modification session.

Task 3.3.2: Develop Recipe Modification UI.
Action: Add a "Modify Recipe" input field or text area near the displayed recipe in RecipeDisplay.tsx. This UI will send user's modification requests (e.g., "make it spicier," "use less oil," "swap chicken for tofu") to the API.

Outcome: Users can provide iterative modification requests for the current recipe.

Task 3.3.3: Refine LLM Prompt for Modifications.
Action: Update the LLM prompt to explicitly instruct it on how to interpret and apply modification requests using the provided conversational context. Ensure the current_conversation_history tag is populated for modification requests.

Outcome: LLM can successfully modify recipes based on user commands.

Phase 4: Deep Personalization with Personal RAG
Goal: Fully integrate and optimize the personal RAG system to deliver highly customized recipe suggestions.

Epic 4.1: Personal Retrieval & LLM Integration

Task 4.1.1: Implement Personal Vector Search Logic.
Action: In pages/api/generate-recipe.ts (before calling the LLM), implement the following:
- Generate an embedding for the user's new ingredient input (text or image-derived).
- Perform a vector similarity search against only that user's saved recipe embeddings in the chosen database:
  - If Neon: Query the pgvector table, explicitly filtering by user_id and using ORDER BY embedding <-> 'new_input_embedding' LIMIT N.
  - If Upstash: Query the Upstash Vector index, using the user's namespace or metadata filter (user_id), and retrieve the top N results.
- Retrieve the full content of these top N relevant saved recipes (e.g., title, ingredients_list, instructions) from the traditional database using their ids. Format them cleanly.

Outcome: Backend can retrieve relevant saved recipes from the user's personal vector space.

Task 4.1.2: Integrate Retrieved Personal Context into LLM Prompt.
Action: Modify the LLM's system prompt to include the retrieved saved recipes' content as additional context.

PRECISE SYSTEM PROMPT EXAMPLE (Augmented for Personal RAG):
You are an expert, creative, and friendly chef named "Chef Feast." Your goal is to help the user cook delicious meals using available ingredients, respecting their preferences and drawing inspiration from their culinary history.

<user_preferences>
{/* Dynamically insert user's preferences JSON here */}
{ "likesSalty": true, "spiceLevel": 4, "preferredCuisines": ["Mediterranean", "Asian"], "dietaryRestrictions": ["gluten-free"], "allergies": ["nuts"], "mealPace": "quick" }
</user_preferences>

<user_saved_recipes_context>
{/* Dynamically insert relevant saved recipes retrieved from personal RAG */}
[
  {
    "title": "Spicy Thai Basil Chicken",
    "ingredients": ["chicken breast", "basil", "fish sauce", "chili peppers"],
    "instructions": "A quick stir-fry known for bold flavors."
  },
  {
    "title": "Mediterranean Chickpea Salad",
    "ingredients": ["chickpeas", "cucumber", "tomato", "feta", "lemon"],
    "instructions": "Light and refreshing salad with a tangy dressing."
  }
]
</user_saved_recipes_context>

<current_conversation_history>
{/* Dynamically insert current conversation history for modifications (LangChain output) */}
</current_conversation_history>

Instructions:
1. Based on the provided current ingredients, the user's general preferences, and the style/ingredients from their saved recipe history, suggest 2-3 unique and practical recipes.
2. Prioritize using the user's provided ingredients. If a saved recipe's style is relevant, consider incorporating similar flavor profiles or techniques.
3. For each recipe, provide:
   a. A creative and enticing title.
   b. A brief, inviting description.
   c. A concise list of required ingredients (including quantities, if reasonable assumptions can be made).
   d. Clear, step-by-step cooking instructions.
   e. An estimated preparation time and cooking time.
4. Ensure recipes strictly adhere to "dietaryRestrictions" and "allergies". Adapt "spiceLevel", "likesSalty", "preferredCuisines", and "mealPace" as much as possible.
5. If an ingredient list seems incomplete or ambiguous for good recipes, suggest logical additions or ask for clarification within your response.
6. Format your response as a JSON array of recipe objects. Each recipe object must have the keys: "title", "description", "ingredients", "instructions", "prepTime", "cookTime".

Outcome: New recipe generations are significantly influenced by the user's saved recipes, providing deeper personalization.

IMPORTANT NOTE ON PROMPT ENGINEERING: The provided system prompts are starting points. Ongoing prompt engineering and experimentation will be essential to optimize recipe quality, adherence to instructions, and overall user satisfaction. Iterative testing with different LLM models and prompt variations will be required throughout the project's lifecycle.

Epic 4.2: Personal RAG Performance & Cost Optimization

Task 4.2.1: Monitor & Optimize Vector DB Performance.
Action: Continuously monitor query latency and cost for pgvector or Upstash Vector. Adjust indexing (e.g., HNSW parameters), batch sizes, and query parameters as needed.

Outcome: Efficient and cost-effective personal RAG operations.

Task 4.2.2: Handle Cold Start / Low Saved Recipes Gracefully.
Action: Implement logic in pages/api/generate-recipe.ts to:
- Check if a user has a minimum number of saved recipes (e.g., > 5) before performing a personal RAG search.
- If not enough saved recipes, either skip the personal RAG step or provide a more generic prompt, possibly with a message to the user encouraging them to save more recipes.

Outcome: Consistent user experience and optimized cost when personal RAG data is sparse.

TECHNICAL NOTES
==============

Understanding Next.js Concepts (For Angular Developers)
As an Angular developer, you can map these concepts:

Pages and Routing (File-System Based): Next.js routes are automatically created from files in the pages directory (e.g., pages/about.tsx -> /about). Similar to Angular's app-routing.module.ts, but implicit. Use next/link for client-side navigation (routerLink).

Rendering (SSR, SSG, ISR, CSR): Next.js offers various ways pages are rendered, unlike Angular's default Client-Side Rendering (CSR).

CSR: Default React component behavior. Similar to standard Angular SPA.
SSR (Server-Side Rendering): Page rendered on server per request. Similar to Angular Universal. (Implemented via getServerSideProps).
SSG (Static Site Generation): Page pre-rendered at build time. Ultra-fast, great for SEO. (Implemented via getStaticProps).
ISR (Incremental Static Regeneration): SSG with periodic revalidation. (Implemented via getStaticProps with revalidate).

Data Fetching:
- Pre-rendering data via getServerSideProps (SSR) or getStaticProps/getStaticPaths (SSG/ISR).
- Client-side fetching using useEffect with fetch or libraries like SWR/React Query (similar to Angular's HttpClient).

API Routes: Next.js allows creating serverless API endpoints within pages/api. No Angular equivalent, it replaces the need for a separate backend server for simple APIs.

Hydration: The process where client-side JavaScript "takes over" static HTML pre-rendered by the server (SSR/SSG), making it interactive. Avoids blank pages and improves SEO. Mismatches (server HTML != client React render) cause errors.

Core React Hooks: useState & useEffect

useState (Component State Management):
- Purpose: Allows functional components to manage reactive local state.
- Analogy (Angular): Similar to componentProperty: type = initialValue; where changing componentProperty triggers change detection.
- Usage: const [stateValue, setStateValue] = useState(initialValue);
- Behavior: setStateValue triggers a component re-render. State updates are asynchronous. Use setStateValue(prevState => prevState + 1) for updates dependent on previous state.

useEffect (Side Effects & Lifecycle):
- Purpose: Perform actions that interact with the "outside world" of the component (data fetching, subscriptions, DOM manipulation, timers).
- Analogy (Angular): Combines ngOnInit (for setup), ngOnChanges (for reacting to prop/state changes), and ngOnDestroy (for cleanup).
- Usage: useEffect(() => { /* effect logic */ return () => { /* cleanup logic */ }; }, [dependencies]);
- Dependency Array []:
  - [] (empty array): Runs once after initial render. Cleanup runs on unmount. (ngOnInit).
  - No array: Runs after every render (rarely desired).
  - [dep1, dep2]: Runs after initial render and when dep1 or dep2 changes. Cleanup runs before re-run or unmount. (ngOnChanges on specific props).
- Cleanup Function (return () => {}): Essential for preventing memory leaks (unsubscribing, clearing timers). Runs before the effect re-executes or component unmounts.

IMPORTANT CONSIDERATIONS for Image Recognition (Review during implementation of Epic 2.1 & 2.2):

Accuracy & Granularity: Google Vision API is very good, but not perfect, especially with specific food items (e.g., distinguishing apple varieties) or in cluttered scenes.
Mitigation: The User Confirmation UI (Task 2.2.1) is our primary defense against misidentification.

Ambiguity & Context: The API might return "vegetable" instead of "broccoli."
Mitigation: User Confirmation UI allows refinement. LLM can be prompted to ask clarifying questions if input is too general.

Lighting, Angles, & Clutter: Poor photo quality impacts accuracy.
Mitigation: Provide clear user instructions on how to take good photos (e.g., "good lighting, minimal clutter, show items clearly"). Client-side optimization (Task 2.1.2) helps with processing, but not initial detection quality.

Cost Management: Vision API calls incur costs.
Mitigation: Client-side image optimization (Task 2.1.2) reduces data transfer. Batch processing (Task 2.1.3) improves efficiency. Implement robust monitoring of API usage.

Data Privacy: User images are sensitive.
Mitigation: Ensure images are handled securely (HTTPS, temporary storage only). Have a clear privacy policy stating how image data is used and not retained indefinitely.

---

Last Updated: January 2025
Current Focus: Phase 2.5 - User Experience Enhancement
Next Milestone: Complete UX improvements before moving to Phase 3